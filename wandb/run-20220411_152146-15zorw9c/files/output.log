
Buckle up, here with start the journey🚲
----------------------ready to use dataset--------------
Found already existing npy
shape of Xs_train:  (3610, 3, 256, 256)
shape of Ys_train:  (3610, 1, 256, 256)
shape of Xt_train:  (3610, 3, 256, 256)
shape of Yt_train:  (3610, 1, 256, 256)
--------------------------------------------------------------------
Number of source training examples: 2166
Number of source validation examples: 1444
Finally atleast train and valid source dataloader section works 😌
--------------------------------------------------------------------
 Shape of Xt_train is:(3610, 3, 256, 256)
--------------------------------------------------------------------
Number of target training examples: 2166
Number of target validation examples: 1444
Finally atleast train and valid target dataloader section works 😌
length of train source:181, lenth of train target is 181
length of validation source:121, lenth of validation target is 121
The model has 31,037,633 trainable parameters
----------------------Traning phase-----------------------------














































































































100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [03:43<00:00,  1.12s/it]
  0%|                                                                                                                                                                 | 0/200 [00:00<?, ?it/s]
Training loss in average for epoch 1 is 200.1853963780403
Training F1 in average for epoch 1 is 0.4650681941211224
Training Accuracy in average for epoch 1 is 0.6596780341863632
Training IOU in average for epoch 1 is 0.306178140565753
Training K in average for epoch 1 is 1.3853685635328292

































 98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉   | 196/200 [01:06<00:01,  2.96it/s]
Evaluation loss in average for epoch 1 is 85.69685151100158
Evaluation F1 in average for epoch 1 is 0.48612369045615195
Evaluation Accuracy in average for epoch 1 is 0.7019575884938241
Evaluation IOU in average for epoch 1 is 0.3244017428904772
Evaluation K in average for epoch 1 is 1.3611462837457657
last learning rate: [0.0005] LR: [0.0005]
###################### Early stopping ##########################
The current validation loss: 85.69685151100158
trigger times: 0
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [01:07<00:00,  2.95it/s]
/share/projects/erasmus/pratichhya_sharma/app/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:416: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "














































































































100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [03:43<00:00,  1.12s/it]
  0%|                                                                                                                                                                 | 0/200 [00:00<?, ?it/s]
Training loss in average for epoch 2 is 49.557136299610136
Training F1 in average for epoch 2 is 0.4768952311575413
Training Accuracy in average for epoch 2 is 0.6779849049448967
Training IOU in average for epoch 2 is 0.31632497258484366
Training K in average for epoch 2 is 1.3734274274110794

































 98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉   | 196/200 [01:06<00:01,  2.97it/s]
Evaluation loss in average for epoch 2 is 29.048565043210985
Evaluation F1 in average for epoch 2 is 0.5011479079723358
Evaluation Accuracy in average for epoch 2 is 0.7222274860739708
Evaluation IOU in average for epoch 2 is 0.33722712241113184
Evaluation K in average for epoch 2 is 1.3398111909627914
last learning rate: [0.0005] LR: [0.0005]
###################### Early stopping ##########################
The current validation loss: 29.048565043210985
trigger times: 0
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [01:07<00:00,  2.96it/s]














































































































100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [03:43<00:00,  1.12s/it]
  0%|▊                                                                                                                                                        | 1/200 [00:00<01:14,  2.67it/s]
Training loss in average for epoch 3 is 48.11172387063503
Training F1 in average for epoch 3 is 0.48314358919858935
Training Accuracy in average for epoch 3 is 0.6887236219644547
Training IOU in average for epoch 3 is 0.3221624848246574
Training K in average for epoch 3 is 1.365016040802002

































 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍ | 198/200 [01:06<00:00,  2.96it/s]
Evaluation loss in average for epoch 3 is 16.3364910030365
Evaluation F1 in average for epoch 3 is 0.49947095446288586
Evaluation Accuracy in average for epoch 3 is 0.7288596034049988
Evaluation IOU in average for epoch 3 is 0.3362205350026488
Evaluation K in average for epoch 3 is 1.33287637591362
last learning rate: [0.0005] LR: [0.0005]
###################### Early stopping ##########################
The current validation loss: 16.3364910030365
trigger times: 0
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [01:07<00:00,  2.96it/s]















































































































100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏| 199/200 [03:43<00:01,  1.14s/it]
Training loss in average for epoch 4 is 38.877006876021625
Training F1 in average for epoch 4 is 0.4788982117176056
Training Accuracy in average for epoch 4 is 0.6929282557964325
Training IOU in average for epoch 4 is 0.31815811976790426
Training K in average for epoch 4 is 1.3646704703569412
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [03:44<00:00,  1.12s/it]








































100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏| 199/200 [01:22<00:00,  1.61it/s]
Evaluation loss in average for epoch 4 is 18.948225585222243
Evaluation F1 in average for epoch 4 is 0.47953912153840067
Evaluation Accuracy in average for epoch 4 is 0.7058251279592515
Evaluation IOU in average for epoch 4 is 0.3191151535511017
Evaluation K in average for epoch 4 is 1.3604148364067077
last learning rate: [0.0005] LR: [0.0005]
###################### Early stopping ##########################
The current validation loss: 18.948225585222243
trigger times: 1
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [01:22<00:00,  2.41it/s]
  0%|                                                                                                                                                                 | 0/200 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/share/mastoc/projects/erasmus/pratichhya_sharma/DAoptim/DAoptim/main.py", line 163, in <module>
    main(net)
  File "/share/mastoc/projects/erasmus/pratichhya_sharma/DAoptim/DAoptim/main.py", line 107, in main
    train_loss, acc_mat = Train.train_epoch(net,optimizer, source_dataloader, target_dataloader)
  File "/share/mastoc/projects/erasmus/pratichhya_sharma/DAoptim/DAoptim/train.py", line 64, in train_epoch
    g_xs, f_g_xs = net(xs)  # source embedded data
  File "/share/projects/erasmus/pratichhya_sharma/app/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/mastoc/projects/erasmus/pratichhya_sharma/DAoptim/DAoptim/model/unet.py", line 68, in forward
    dec1 = self.upconv1(dec2)
  File "/share/projects/erasmus/pratichhya_sharma/app/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/projects/erasmus/pratichhya_sharma/app/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 923, in forward
    return F.conv_transpose2d(
RuntimeError: CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 15.78 GiB total capacity; 3.91 GiB already allocated; 127.69 MiB free; 3.95 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF